from scipy.stats import entropy as en
from scipy import stats
import pandas as pd
import numpy as np
from math import log, e
from collections import Counter
check = open(r'C:\Human\Hexadecimal Bytes50.txt')
data = check.read()
data = data.split(",")
# check.truncate(0);

i=0
datex = []
for j in range (1024, len(data)+1, 1024):
   check_data = data[i:j]
   # check_array = np.array(check_data)
   entropy = stats.entropy(list(Counter(check_data).values()), base=2)
   # print(entropy)
   for cccc in check_data:
       Replacement = [check_data.count(cccc), entropy]
       datex.append(Replacement)
       
       # check.writelines(datax);
   i=i+1024

datex = pd.DataFrame(datex)
datex.columns = ['frequency', 'entropy']



from matplotlib.pyplot import hist
import matplotlib.pyplot as plt
# plt.figure(figsize=(12,6))
plt.hist([datex.entropy],bins = 16, alpha=0.5)
plt.show()

# from matplotlib.pyplot import hist

# plt.figure(figsize=(12,6))
plt.hist([datex.frequency],bins = 16, alpha=0.5)
plt.show()





# from sklearn.cluster import KMeans
# import pandas as pd
# from sklearn.preprocessing import MinMaxScaler
# from matplotlib import pyplot as plt

# df = datex
# plt.scatter(df['entropy'],df['frequency'])
# plt.xlabel('entropy')
# plt.ylabel('frequency')

# km = KMeans(n_clusters=2)
# y_predicted = km.fit_predict(df[['entropy','frequency']])
# y_predicted

# df['cluster']=y_predicted
# df.head()

# km.cluster_centers_

# df1 = df[df.cluster==0]
# df2 = df[df.cluster==1]
# df3 = df[df.cluster==2]
# plt.scatter(df1.entropy,df1['frequency'],color='green')
# plt.scatter(df2.entropy,df2['frequency'],color='red')
# plt.scatter(df3.entropy,df3['frequency'],color='black')
# plt.scatter(km.cluster_centers_[:,0],km.cluster_centers_[:,1],color='purple',marker='*',label='centroid')
# plt.xlabel('entropy')
# plt.ylabel('frequency')
# plt.legend()

# scaler = MinMaxScaler()

# scaler.fit(df[['frequency']])
# df['frequency'] = scaler.transform(df[['frequency']])

# scaler.fit(df[['entropy']])
# df['entropy'] = scaler.transform(df[['entropy']])

# df.head()

# plt.scatter(df.entropy,df['frequency'])

# km = KMeans(n_clusters=2)
# y_predicted = km.fit_predict(df[['entropy','frequency']])
# y_predicted

# df['cluster']=y_predicted
# df.head()

# km.cluster_centers_

# df1 = df[df.cluster==0]
# df2 = df[df.cluster==1]
# df3 = df[df.cluster==2]
# plt.scatter(df1.entropy,df1['frequency'],color='green')
# plt.scatter(df2.entropy,df2['frequency'],color='red')
# plt.scatter(df3.entropy,df3['frequency'],color='black')
# plt.scatter(km.cluster_centers_[:,0],km.cluster_centers_[:,1],color='purple',marker='*',label='centroid')
# plt.legend()

# #elbow plot
# sse = []
# k_rng = range(1,10)
# for k in k_rng:
#     km = KMeans(n_clusters=k)
#     km.fit(df[['entropy','frequency']])
#     sse.append(km.inertia_)
    
# plt.xlabel('K')
# plt.ylabel('Sum of squared error')
# plt.plot(k_rng,sse)